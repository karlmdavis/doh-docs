= SandersonSetupAfsServer =

This SandersonSetup sub-guide documents the step necessary to make the computer a backup AFS server.


== Debian Documentation ==

The Debian documentation for OpenAFS is an excellent source of information for OpenAFS.  Once the AFS packages have been installed, they can be found in the various `/usr/share/doc/openafs-*` folders.  It is '''strongly''' recommended that you read through these.

To unzip the documentation `.gz` files, run a command like the following:
{{{
# gunzip /usr/share/doc/openafs-dbserver/*.gz
}}}


== Install OpenAFS Client ==

Just as a bit of a primer, it makes sense to first install the OpenAFS client.  Follow these steps:
 1. First build and install the OpenAFS kernel module:
{{{
# apt-get install openafs-modules-source openafs-doc module-assistant
# module-assistant prepare openafs-modules
# module-assistant auto-build openafs-modules
# dpkg -i /usr/src/openafs-modules-<version>.deb
}}}
 1. Install the rest of the client:
{{{
apt-get install openafs-client
}}}
 1. When prompted, enter/select the following options:
    1. AFS cell this workstation belongs to: `davisonlinehome.name`
    1. Size of AFS cache in kB: `500000`
    1. DB server host names for your home cell: `eddings.davisonlinehome.name`
    1. Run Openafs client now and at boot?: ''Yes''
 1. To verify that the client is working, run the following command, which should list some folders:
{{{
$ ls /afs/davisonlinehome.name
}}}
 1. Install the tools required to authenticate to Kerberos and OpenAFS:
{{{
# apt-get install krb5-user openafs-krb5
}}}
 1. Edit `/etc/krb5.conf` to add the DAVISONLINEHOME.NAME realm:
{{{
[libdefaults]
	default_realm = DAVISONLINEHOME.NAME
...
[realms]
	DAVISONLINEHOME.NAME = {
		kdc = kerberos.davisonlinehome.name
		admin_server = kerberos.davisonlinehome.name
		default_domain = davisonlinehome.name
	}
...
[domain_realm]
	.davisonlinehome.name = DAVISONLINEHOME.NAME
	davisonlinehome.name = DAVISONLINEHOME.NAME
...
}}}
 1. Test to ensure everything is working (these commands should not generate any errors):
{{{
$ kinit <username>
$ aklog
}}}


== Install OpenAFS Server ==

With the client working, follow the next steps to install the server:
 1. Install the server packages:
{{{
# apt-get install openafs-dbserver openafs-fileserver
}}}

Stop here for a bit and actually read the Debian documentation for OpenAFS.  It should be considered required reading before following any of the next steps.  In particular, the "Adding Additional Servers" section of `/usr/share/doc/openafs-*/README.servers` describes (more-or-less) everything in this section in far greater detail than here.

Continue on with the installation:
 1. Copy the configuration files from `/etc/openafs/server` on an existing server to the same location on the new server (replace `user` and `*server` with the appropriate usernames and hostnames):
{{{
user@oldserver# scp -pr /etc/openafs/server/ user@newserver:/home/user
user@newserver# cp -a /home/user/server /etc/openafs/
user@newserver# chown -R root:root /etc/openafs/server
}}}
 1. Setup a fileserver service on the new server:
{{{
# bos create sanderson fs fs -cmd "/usr/lib/openafs/fileserver \
              -p 23 -busyat 600 -rxpck 400 -s 1200 -l 1200 -cb 65535 -b 240 -vc 1200" \
              -cmd /usr/lib/openafs/volserver \
              -cmd /usr/lib/openafs/salvager -localauth
}}}
 1. Add the new server as a DB server on each server, including all old DB servers and the new one.  Run the following command on each server, replacing "`<server>` and `<new-server>`, as appropriate):
{{{
# bos addhost <server> <new-server> -localauth

e.g.:
user@oldserver# bos addhost oldserver.domain newserver.domain -localauth
user@newserver# bos addhost newserver.domain newserver.domain -localauth
}}}
 1. Restart the protection and volume services on each pre-existing server (wait a few seconds before moving on to the next server):
{{{
# bos restart <server> ptserver -localauth
# bos restart <server> vlserver -localauth
}}}
 1. Create the protection and volume service instances on the new server:
{{{
# bos create <host> ptserver simple /usr/lib/openafs/ptserver -localauth
# bos create <host> vlserver simple /usr/lib/openafs/vlserver -localauth
}}}

Since this server will be an off-site backup server for disaster recovery, it's best that none of the clients know of it.  OpenAFS clients will always go to the server with the lowest or closest IP (I can't recall which); there's no way beyond that to control which servers they access first.  However, if clients should be accessing this server (e.g. if it should be available to clients for when the other servers are down), this new server should have an `AFSDB` DNS entry created for it and/or be added to each client's `CellServDB` file.

To confirm that the installation went correctly, run the following commands:
 1. Authenticate to AFS:
{{{
$ kinit <afs-admin-username>
$ aklog
}}}
 1. Check the services' state on the new server:
{{{
$ bos status -server <server>
}}}


== Creating OpenAFS "vice" partitions ==

OpenAFS stores volumes in one or many "vice" partitions on each volume server: `/vicepa`, `/vicepb`, etc.  To resize the existing partitions and create a new vice partition, the server will have to be rebooted into a Live CD environment with access to `gparted`.  Since this server has no CD drive, use the `usb-creator` tool to create a "Live CD" on a flash drive.

After booting into the Live CD environment, start the `gparted` tool and create a new `ext2` partition.  Once done, reboot back into the server's normal operating system.

Mount the new partition as `vicepa`:
 1. Find the device node for the partition (e.g. `/dev/sda6`):
{{{
# fdisk -l
}}}
 1. Find the partition's UUID:
{{{
# vol_id -u /dev/sda6
}}}
 1. Create the mount point:
{{{
# mkdir /vicepa
}}}
 1. Edit the `/etc/fstab` file and add an entry similar to the following (replace the device node and UUID with the values noted earlier):
{{{
# /dev/sda6
UUID=01216790-e244-41b2-b2e0-d2bb7d0a525c /vicepa         ext2    defaults 0       2
}}}
 1. Mount all of the fstab entries:
{{{
# mount -a
}}}
 1. Ensure that the new partition was mounted correctly (should see at least a `lost+found` folder):
{{{
$ ls /vicepa
}}}


== Creating Shadow Backup Volumes ==

References:
 * [http://www.dementia.org/twiki/bin/view/AFSLore/AdminFAQ#3_50_What_is_a_Shadow]
 * [http://workshop.openafs.org/afsbpw06/talks/drh.scs.pdf]
 * [http://www.openafs.org/pipermail/openafs-info/2007-June/026540.html]

The `vos shadow` command is a relatively recent addition to the OpenAFS suite.  It can be used to create copies of volumes that, unlike read-only copies, are not live and will not be accessed by clients.  These shadow volumes can be updated incrementally and seem to be quite useful as part of a disaster recovery plan: if a "real" volume server goes down, the shadow clones of its volumes can be pushed live.

As of this writing, the Debian version of OpenAFS did not have a man page for this command.  For syntax help with `vos shadow`, run:
{{{
$ vos help shadow
}}}

To create a shadow of an existing volume from a "live" server on the new backup server, run a command like the following (replace with the correct details, as appropriate):
{{{
$ vos shadow -id root.afs -fromserver asimov.davisonlinehome.name -frompartition a -toserver sanderson.davisonlinehome.name -topartition a
}}}

To update an existing shadow incrementally, run a command like the following:
{{{
$ vos shadow -id root.afs -fromserver asimov.davisonlinehome.name -frompartition a -toserver sanderson.davisonlinehome.name -topartition a -incremental
}}}

Please note that shadow volumes must be removed (`vos remove`) and then recreated if the volume they are shadowing is moved or renamed.


== Installing OpenAFS Backports ==

Unfortunately, Hardy only has the quite-outdated 1.4.6 version of OpenAFS.  According to [http://www.ece.cmu.edu/~allbery/lambdabot/logs/openafs/2009-08-24.txt], shadow volumes (and most everything) aren't well-supported in this version.

Karmic has 1.4.11 but this hasn't made its way into the official `hardy-backports` repository.  However, [https://launchpad.net/%7Eanders-kaseorg anders-kaseorg] has made backports available in a PPA.  To add this PPA and upgrade to Karmic's version of OpenAFS, do the following:
 1. Add the following lines to the end of `/etc/apt/sources.list`:
{{{
# Contains backports of OpenAFS from Karmic
deb http://ppa.launchpad.net/anders-kaseorg/openafs/ubuntu hardy main
}}}
 1. Install this PPA repository's signing key by running the following command:
{{{
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 413576CB
}}}
 1. Update and upgrade via APT:
{{{
# apt-get update
# apt-get upgrade
}}}
 1. Remove all of the currently-installed kernel module packages:
    1. Get a list of all the currently-installed packages by running the following command:
{{{
# dpkg -l openafs-modules-2.6-*
}}}
    1. Remove each of those packages by running the following command once for each package (replace the version number with the version numbers for each installed package):
{{{
# dpkg --purge openafs-modules-2.6.24-23-server
}}}
 1. Install the `openafs-modules-dkms` package.  Installing this package will ensure that the OpenAFS kernel modules are built automatically, when needed.  Run the following command:
{{{
# apt-get install openafs-modules-dkms
}}}
 1. Reboot the server:
{{{
# reboot
}}}
